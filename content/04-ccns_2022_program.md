+++
title = "04 - CCNS 2022 Program"
weight = 20
draft = false
+++

### CCNSv3 will take place on June 6-7, 2022, and registration is open [here](https://www.crowdcast.io/e/ccnsv3/register).

### Submit your abstract for a Trainee Talk [here](https://forms.gle/thSZWMyr4uxHQLJi9) by May 23 for full consideration.

## Program
### Monday, June 6
* 8:45 AM EDT: **Welcome and Introduction: Dr. Scott Rich**
* 9:00 AM EDT: **Tutorial Talk: Dr. Alexandra Chatzikalymniou** (Neural Circuit Modeling)
* 9:25 AM EDT: **Dr. Willy Wong** (Neural Circuit Modeling) 
* 9:50 AM EDT: **Break**
* 10:00 AM EDT: **Dr. Steven Prescott** (Neural Circuit Modeling) 
* 10:25 AM EDT: **Dr. Carmen Canavier** (Neural Circuit Modeling)
* 10:50 AM EDT: **Break**
* 11:00 AM EDT: **Keynote Address: Dr. Gaute Einevoll** (Neural Circuit Modeling)
* 12:00 PM EDT: **Lunch Break**
* 1:00 PM EDT: **Tutorial Talk** (Neuro-AI)
* 1:25 PM EDT: **Dr. Richard Naud** (Neuro-AI)
* 2:00 PM EDT: **Break**
* 2:10 PM EDT: **Dr. Milad Lankarany** (Neuro-AI)
* 2:45 PM EDT: **Dr. Blake Richards** (Neuro-AI)
* 3:20 PM EDT: **Break**
* 3:25 PM EDT: **Dr. Wilten Nicola** (Neuro-AI)
* 4:00 PM EDT: **Break**
* 4:05 PM EDT: **Trainee Spotlight Talks: Laura Medlock and Ann Huang**
* 4:40 PM EDT: **Parallel Trainee Talks**


### Tuesday, June 7
* 8:40 AM EDT: **Trainee Spotlight Talks: Andrea Luppi and Annemarie Wolff**
* 9:15 AM EDT: **Parallel Trainee Talks**
* 9:45 AM EDT: **Break**
* 9:50 AM EDT: **Tutorial Talk: Dr. Kelly Shen** (Large-Scale Brain Modeling)
* 10:15 AM EDT: **Dr. Davide Momi** (Large-Scale Brain Modeling)
* 10:40 AM EDT: **Break**
* 10:50 AM EDT: **Laura Suarez** (Large-Scale Brain Modeling)
* 11:15 AM EDT: **Dr. Jeremie Lefebvre** (Large-Scale Brain Modeling)
* 11:40 AM EDT: **Break**
* 11:50 PM EDT: **Keynote Address: Dr. Viktor Jirsa** (Large-Scale Brain Modeling)
* 12:50 PM EDT: **Lunch Break**
* 1:20 PM EDT: **Panel Discussion**
* 2:00 PM EDT: **Dr. Jacqueline Scholl** (Cognitive Modeling)
* 2:35 PM EDT: **Casper Hesp** (Cognitive Modeling)
* 3:10 PM EDT: **Break**
* 3:20 PM EDT: **Tutorial Talk: Dr. Andreea Diaconescu** (Cognitive Modeling)
* 3:45 PM EDT: **Break**
* 3:50 PM EDT: **Keynote Address: Dr. Cendri Hutcherson** (Cognitive Modeling)
* 4:50 PM EDT: **Concluding Remarks**

## Trainee Abstracts
### Monday Spotlight Talks
* **Laura Medlock**: Pain-related sensory input is processed in the spinal dorsal horn (SDH) before being relayed to the brain. That processing profoundly influences whether tactile stimuli are correctly or incorrectly perceived as painful. Different types of excitatory and inhibitory neurons have been identified in the SDH, and some of their connectivity is understood, but how the overall circuit processes sensory input or how that processing is disrupted under chronic pain conditions remains unclear. To explore sensory processing in the SDH, we developed a computational model of the circuit that is tightly constrained by experimental data. Our model comprises conductance-based neuron models that reproduce the characteristic firing patterns of spinal neurons. Different spinal neuron populations were synaptically connected according to available qualitative data. Using a genetic algorithm, synaptic weights were optimized to reproduce projection neuron firing rates (model output) in response to primary afferent firing rates (model input) across a range of mechanical stimulus intensities. This optimization revealed that distinct synaptic weight combinations could produce equivalent SDH circuit function, revealing degeneracy that may underlie heterogeneous responses of different circuits to perturbations or pathological insults. To validate our model, we verified that it responded to reduction of inhibition (i.e. disinhibition) and ablation of specific neuron types in a manner consistent with experiments. Our validated model offers a valuable resource for interpreting experimental results and testing hypotheses in silico to plan experiments for examining normal and pathological SDH circuit function.
* **Ann Huang**: The ability to encode “what happened when” is central to the accurate representation of episodic memory. Previous neurophysiology studies have reported groups of cells that fire sequentially during the delay period of working memory tasks. These cells are commonly called “time cells” because they are thought to serve as the neural substrates for tracking time. However, the representation of time in “time cells” is confounded by other task variables, such as the animal’s running speed, spatial location, and sensory experience. Previous studies that used statistical methods to parse the information encoded by “time cells” are also fundamentally flawed in their statistical assumptions. Here we hypothesize that rather than encoding the time elapsed per se, the so-called “time cells” emerge as an epiphenomenon when encoding any behaviorally relevant variables that unroll over time. We trained an artificial agent on a Trial-Unique Nonmatch-to-Location (TUNL) working memory task and recorded the activity from the recurrent neural network of the artificial agent. Using neuroscience-based and information-theoretic analysis, we showed that (1) apparent “time cells” emerge in the recurrent neural network during the task (2) “time cells” show heterogeneous representations of time elapsed, spatial location, and incoming sensory stimuli (3) the apparent “time cells” are more strongly modulated by spatial location rather than time elapsed during the task. Our study serves as a proof of principle that in recurrent neural networks trained on working memory tasks, the apparent “time cells” represent behaviorally relevant variables that unfolds in time rather than the time elapsed per se. 
### Tuesday Spotlight Talks
* **Andrea Luppi**: A fundamental question in neuroscience is how brain organisation gives rise to humans’ unique cognitive abilities. Although complex cognition is widely assumed to rely on frontal and parietal brain regions, the underlying mechanisms remain elusive: current approaches are unable to disentangle different forms of information processing in the brain. Here, we introduce a powerful framework to identify synergistic and redundant contributions to neural information processing and cognition. Leveraging multimodal data including functional MRI, PET, cytoarchitectonics and genetics, we reveal that synergistic interactions are the fundamental drivers of complex human cognition. Whereas redundant information dominates sensorimotor areas, synergistic activity is closely associated with the brain’s prefrontal-parietal and default networks; furthermore, meta-analytic results demonstrate a close relationship between high-level cognitive tasks and synergistic information. From an evolutionary perspective, the human brain exhibits higher prevalence of synergistic information than non-human primates. At the macroscale, we demonstrate that high-synergy regions underwent the highest degree of evolutionary cortical expansion. At the microscale, human-accelerated genes promote synergistic interactions by enhancing synaptic transmission. These convergent results provide critical insights that synergistic neural interactions underlie the evolution and functioning of humans’ sophisticated cognitive abilities, and demonstrate the power of our widely applicable information decomposition framework.
* **Annemarie Wolff**: Studies of perception and cognition in schizophrenia (SCZ) show neuronal background noise (ongoing activity) to intermittently overwhelm the processing of external stimuli. This increased noise, relative to the activity evoked by the stimulus, results in temporal imprecision and higher variability of behavioral responses. What, however, are the neural correlates of temporal imprecision in SCZ behavior? We first report a decrease in electroencephalography signal-to-noise ratio (SNR) in two SCZ datasets and tasks in the broadband (1–80 Hz), theta (4–8 Hz), and alpha (8–13 Hz) bands. SCZ participants also show lower inter-trial phase coherence (ITPC)— consistency over trials in the phase of the signal—in theta. From these ITPC results, we varied phase offsets in a computational simulation, which illustrated phase-based temporal desynchronization; our simulations show that higher phase shifting leads to lower phase coherence over trials. This modeling also provided a necessary link to our results and showed decreased neural synchrony in SCZ in both datasets, sensory modalities (visual, auditory) and tasks when compared with healthy controls. Finally, we showed that reduced SNR and ITPC are related and showed a relationship to temporal precision on the behavioral level, namely reaction times. Interestingly, ITPC and SNR predict reaction times in healthy controls, but not in SCZ participants. In conclusion, we demonstrate how temporal imprecision in SCZ neural activity—reduced relative signal strength and phase coherence—mediates temporal imprecision on the behavioral level.
### Monday Parallel Talks
#### Room 1
* **Pascal Helson**: Parkinson's Disease (PD) is known for its motor symptoms. However, many reasons (non-motor symptoms, brain-wide projections of neuromodulators such as dopamine, complexity of brain regions (BRs) interactions) suggest that many BRs are simultaneously affected in PD. Despite that, most research on PD is concentrated on basal ganglia and sensorimotor BRs. In this study, we aim at getting more insights into neuronal activity changes distributed across the whole brain in PD. To do so, we performed a source level analysis on resting state magnetoencephalogram (MEG) from two groups: PD patients and healthy controls. After a spectral analysis, we quantified the aperiodic activity by fitting a power law (κ/f^λ) to the MEG spectrum and then studied its relationship with age and UPDRS. Consistent with previous results, the most significant spectral changes were observed in the low alpha-band (8-10Hz) in all BRs. On the other hand, recent work has shown that the aperiodic part of the spectrum, usually ignored, allows inferring the Excitation-Inhibition (EI) ratio through λ. We found that in all but frontal regions, λ was significantly larger in PD patients than in control subjects. Larger value of λ in PD implies reduced excitation or increased inhibition or both. Furthermore, λ was correlated with patient age and UPDRS. Our results indicate for the first time that PD is associated with change in EI ratio across the whole brain. Moreover, our results provide means to extract new information from MEG which can be used in modelling and developed into new biomarkers of PD.
* **Afroditi Talidou**: The generation and propagation of action potentials in white matter are influenced by a fatty substance, called myelin, wrapping around axons. Myelin is formed by glial cells -- oligodendrocytes -- and allows action potentials to transmit faster and without attenuation. An important feature of myelin is its impact on conduction delays, that is, the time it takes for action potentials to reach their destination. Conduction delays play an important role in brain function due to the dependence of neural communication on spike timing. Thus studying conduction delays is of the utmost importance. Previous studies examining action potential propagation along myelinated axons are based on stereotyped cases assuming that myelin sheaths are periodically located along axons and are thus very symmetric. The question we aim to answer is: do changes in myelin segment distribution, length and thickness, not only along the same axon but also along different axons, influence conduction delays and neural communication across the white matter? We are making a step forward answering this question and estimate conduction delays and the corresponding conduction velocity in the more general case where myelin sheaths of different longitudinal lengths and widths are randomly distributed along single axons. The lengths of nodes of Ranvier, namely the gaps between two consecutive myelin, will also change. How will this impact the propagation of action potentials? What are other parameters affecting conduction delays? We approach the problem using the cable equation and provide both computational and mathematical analysis whenever possible.
* **Loïc Azzalini**: Background: Thanks to massively parallel computational architectures and spike-based communication, neuromorphic hardware holds great promise in the field of computational neuroscience to simulate large neural models in real-time. Dedicated hardware allows models of the brain to be placed in the physical world where environmental effects and interactions may be investigated.   The exploration of deep brain stimulation (DBS) effects lends itself well to such brain-in-the-loop simulation. To this end, it is crucial to first simulate realistic neuronal dynamics on neuromorphic hardware. Hypothesis: Neuromorphic hardware provides a biophysically realistic computational framework to study the effects of deep brain stimulation in real-time. Materials and Methods: Recent work explored the role played by DBS-induced short-term synaptic plasticity (STP) in single-neuron recordings from patients with movement disorders. The computational framework used in this study is revisited and made compatible to run on the SpiNNaker neuromorphic hardware. Specifically, the sPyNNaker computational framework is extended to support DBS-induced plasticity and STP, based on the phenomenological Tsodyks-Markram (TM) model. Results: We recently implemented STP dynamics for the SpiNNaker system which previously only supported long-term plasticity (e.g. STDP). Building on this milestone, we developed a model for DBS-induced STP. Conclusion: Moving forward, we aim to implement a model of the basal ganglia neuronal network using biophysically realistic models developed in the NSBSPL. This will support investigations into DBS impact, in real-time, on different substructures of the basal ganglia and at different scales.
#### Room 2
* **Benjamin Barlow**: In a variety of neurons, action potentials (APs) initiate at the proximal axon, within a region called the axon initial segment (AIS). Pyramidal neurons concentrate high-threshold sodium channels (Nav1.2) in the proximal AIS, and the distal AIS contains mostly lower threshold Nav1.6. It has been argued that this separated Nav distribution favours backpropagation. However, our simulations show that this distribution actually impedes backpropagation when the neuron is stimulated somatically. We implemented a range of hypothetical Nav distributions in the AIS of a multicompartmental pyramidal cell model. When a stimulating current is injected at the soma, the intrinsic right-shift of Nav1.2 activation causes these channels to raise the backpropagation threshold. However, with axonal stimulation, the right-shift of Nav1.2 availability dominates, such that concentrating Nav1.2 in the proximal AIS promotes backpropagation. Our results imply that regulation of Nav separation can sensitively control backpropagation.
* **Chitaranjan Mahapatra**: Mathematical Modeling of Putative Coupling between cAMP/PKA Pathway and T- Type Ca2+ Channels to Investigate Excitability Properties in Layer II Stellate Cells   The firing patterns of stellate cells in layer II of medial entorhinal cortex are involved in memory, cognition and perception. These patterns are largely modulated by the underlying subcellular calcium dynamics within the axon initial segment (AIS). Recent experimental data have suggested a putative coupling between dopamine D2 receptors (D2R) and T-type Ca2+ channels via a series of sub cellular mechanisms as another biophysical explanation for the firing pattern modulation. Both the cAMP-PKA pathway and the calcium influx are involved in D2R -induced firing pattern alternations. This in silico study aims to enhance our understanding of the calcium influx through T-type Ca2+ channels via cAMP-PKA pathway within AIS of the layer II stellate cells. This simulation study also shows their modulating effects on resting membrane potential (RMP) and action potential (AP) plasticity in pathological conditions. 
* **Zhenyang Sun**: Reduced but not diminished: single-compartment oriens lacunosum-moleculare (OLM) cell model captures detailed model behavior and explains theta resonance in OLM cells Authors: Zhenyang Sun, Frances K Skinner Abstract:  Conductance-based cell models enable theoretical explorations in experimentally untenable situations. With advances in cell imaging and computational power, multi-compartment models with morphological accuracy are becoming common practice. Details increase model biophysical accuracy, but also muddle interpretability. Thus, model reduction is necessary to find the balance between biophysical fidelity and understanding.  We use our developed state-of-art multi-compartment OLM cell model and reduce it to a single compartment model via “biophysical preservation constraints”, and using current injection data as a basis for comparison. We examine the biophysical fidelity of the reduced model by comparing analyses using it with those done using the full, multi-compartment model.  Our reduced model produces results comparable to that of the full model.  That is, it can capture both in vitro and in vivo complex behaviors of the original model as well as a theta frequency spiking resonance, defining feature of the OLM cell type.  We then use the reduced model to show that hyperpolarization-activated inward channels could be responsible for preference to theta resonant frequencies.  In addition to further analyses to decipher the interacting biophysical dynamics, this reduced model could be used as a template to interface with experimental recordings for direct parameter estimation of biophysical characteristics.
#### Room 3
* **Akram Shourkeshti**: In uncertain environments, we generally exploit rewarding opportunities but sometimes explore uncertain alternatives that could be better. At the onset of exploration, neuronal activity patterns in the prefrontal cortex suddenly disorganize, which could promote discovery and learning. Although the mechanisms behind this disorganization remain unknown, one possibility is pupil-linked neuromodulatory systems. However, it is not clear whether pupil size predicts neural signatures of exploration or transitions to exploration. Here, we simultaneously measured pupil size and neuronal activity in the prefrontal cortex while two rhesus macaques made decisions in a dynamic environment that encouraged both exploration and exploitation. We found that pupil size was larger during exploration than exploitation and predicted disorganized patterns of prefrontal activity in both single neurons and populations. The pupil also exhibited surprising trial-by-trial dynamics: it grew larger across trials before exploration, then abruptly decreased to below-baseline levels. Because pupil size dropped immediately after the first explore trial, pupil-linked mechanisms may anticipate the start of exploration, without being sustained throughout periods of exploration. Pupil size predicted our observation of a general slowdown of both response time and neural activity before the start of exploration, suggesting that the onset of exploration signals a critical "tipping point" in prefrontal dynamics. In sum, we found that pupil size tracked both exploratory behavior and its neural correlates, supporting models linking pupil-linked mechanisms with these phenomena. However, the trial-by-trial dynamics of these effects implicate pupil-linked mechanisms in the critical transition at the onset of exploration, rather than in sustaining exploration over time.
* **Leanne Monteiro**: There are well-known sex differences in visual perception, and the visual cortex (V1C) is >20% larger in males than females. Nevertheless, the issue of sex differences in V1C development has not been well-studied. Myelin is a complex multiprotein that has been shown to serve multiple roles in V1C development and plasticity. In the critical period, an increase in myelin-derived signaling puts the ‘brakes’ on developmental plasticity. Paradoxically, in adult V1C, myelin increases in response to enriched sensory experience suggesting that it facilitates plasticity. Together, these raise the question of whether the molecular composition of myelin differs by age and sex? To address this, we analyzed the development of 58 myelin-associated genes using a transcriptomic database from post-mortem tissue samples of the human V1C (n=48). We characterized the lifespan changes by fitting locally estimated scatterplot smoothing curves for each gene and sex pair. We noticed that while some genes showed monotonic increase/decrease across the lifespan, others had an undulating pattern unique to adolescence coinciding with the end of the sensitive period in the human V1C. Second, we conducted hierarchical clustering and found 8 distinct trajectories that describe the developmental profile of myelin. We listed the genes in each trajectory cluster and found minimal overlap between the sexes. This trajectory analysis identified robust age- and sex-related differences in the development of myelin genes in human V1C. These novel findings suggest that myelin may play different roles in transitioning from juvenile to adult plasticity in V1C of females and males.
* **Urvi Mishra**: Title: Classification of motor planning into overt or imagery using an ECoG signal    ECoG provides a fine spatial and temporal resolution of neural activity at a wide scale of locations. In the field of brain computer interfaces (BCI), this can give insight into what neural populations are active during a certain task and how their activity is characterised. Neurally integrated robotic prosthetics hold the potential to help people better regain lost function compared to traditional prosthetics. In order to accurately execute movement, the prosthetic must “know” whether a person means to move now, intends to move later, or is just thinking about a movement with no plan of performing it.   With the motor imagery dataset, we intend to build a binary classifier to differentiate overt movement (intention to actually carry out a movement) and motor imagery (planning a movement without actually executing it). As observed in Miller et al. 2010, the spatial distribution of neural activity is similar for both overt movement or motor imagery innervating the same body part, while the PSD characteristics are different. By training the classifier, our goal is to have an accurate prediction of overt/imagery movement given the ground truth labels provided by the dataset.  We will train our model on a specific body part, and see if parameters from one model generalize to another body part - in other words determining if overt or imagined movement has unique dynamics regardless of specific muscle movement.
### Tuesday Parallel Talks
#### Room 1
* **Parker Singleton**: Psychedelics like lysergic acid diethylamide (LSD) and psilocybin offer a powerful window into the function of the human brain and mind, by temporarily altering subjective experience through their neurochemical effects. A recent model postulates that serotonin 2a (5-HT2a) receptor agonism allows the brain to explore its dynamic landscape more readily, as reflected by more diverse (entropic) brain activity. We postulate that this increase in entropy may arise in part from a flattening of the brain’s control energy landscape, which can be observed using network control theory to quantify the energy required to transition between recurrent brain states measured using functional magnetic resonance imaging (fMRI) in individuals under LSD, psilocybin, and placebo conditions. We show that LSD and psilocybin reduce the amount of control energy required for brain state transitions, and, furthermore, that, across individuals, LSD’s reduction in control energy correlates with more frequent state transitions and increased entropy of brain state dynamics. Through network control analysis that incorporates the spatial distribution of 5-HT2a receptors from publicly available (non-drug) positron emission tomography (PET) maps, we demonstrate the specific role of this receptor in reducing control energy. Our findings provide evidence that 5-HT2a receptor agonist compounds allow for more facile state transitions and more temporally diverse brain activity. More broadly, by combining receptor-informed network control theory with pharmacological modulation, our work highlights the potential of this approach in studying the impacts of targeted neuropharmacological manipulation on brain activity dynamics.
* **Sebastian Idesis**: The understanding of the stroke lesions’ consequences is limited, relying mostly on behavioral reports and mere descriptive correlational information from neuroimaging techniques. Here we demonstrate that utilizing structural disconnection maps describing the specific damages in the anatomical connectivity of individual patients crucially allows the construction of a causal mechanistic generative whole-brain model that is able to explain the functional and behavioral consequences of the stroke lesions. Classification of the stroke behavior severity showed a higher accuracy compared to the most common techniques. Using topological measures characterizing the functional effects of the damages, we were able to understand how network dynamics change emerge in a nontrivial way after a stroke injury of the underlying complex brain system. The results underlined the relevance of adding structural disconnection information to the model to allow for a more personalized treatment which in turn would lead to an improved recovery of the patients. Furthermore, it opens the possibility to apply external manipulations such as neurostimulation in order to treat such a word-wide disease as stroke lesions.
#### Room 2
* **Liang Chen**: In the paper, we derive and analyze a set of exact mean-field equations for the network of Izhikevich neurons, where each neuron is modelled by a two dimensional system consisting of a quadratic integrate and fire equation plus an equation which implements spike frequency adaptation. Previous work deriving a mean-field model for this type of network, relied on the assumption of sufficiently slow dynamics of the adaptation variable. However, this approximation did not succeed in establishing an exact correspondence between the macroscopic description and the realistic neural network, especially when the adaptation time constant was not large. The challenge lies in how to achieve a closed set of mean-field equations with the inclusion of the mean-field expression of the adaptation variable. We address this problem by using a Lorentzian ansatz combined with the moment closure approach to arrive at a mean-field system in the thermodynamic limit. The resulting macroscopic description is capable of qualitatively and quantitatively describing the collective dynamics of the neural network, including transition between states where the individual neurons exhibit tonic firing and bursting. We extend the approach to a network of two populations of neurons and discuss the accuracy and efficacy of our mean-field approximations by examining all assumptions that are imposed during the derivation. Numerical bifurcation analysis of our mean-field models reveal bifurcations not previously observed in the models, including a novel mechanism for emergence of bursting in the network.
* **Alexander G Ginsberg**: We present a mean-field formalism for modeling firing-rate statistics of brain regions whose neurons exhibit atypical firing patterns and heterogeneous electrophysiological properties. We apply the formalism to the suprachiasmatic nucleus (SCN)–-the human circadian pacemaker–-whose neurons can intrinsically exhibit depolarized low-amplitude membrane oscillations (DLAMOs), depolarization block (DB), and standard action potential firing at different times of day. Further, GABA reversal potentials and molecular circadian phases of SCN neurons, among other properties, vary across the network and/or slowly over time. Our formalism consists of a system of integro-differential equations describing the time evolution of the mean and standard deviation of synaptic conductances across the network. Electrophysiological properties of SCN neurons are incorporated by computing responses to synaptic conductance inputs of a Hodgkin-Huxley-type SCN neuron model that exhibits DLAMOs and DB. Such responses are then averaged over distributions of relevant quantities and included in the differential equations. Results suggest mechanisms by which physiologically relevant changes to firing activities may arise, highlighting means by which the amplitude of firing rates may shrink, the standard deviation of firing rates may grow, and by which a mid-day dip in firing rates may appear. For instance, results show that a large spread in circadian phases across SCN neurons reduces the size of oscillations in SCN network firing activity across the 24h day, identifying a mechanism by which heterogeneities in neuron electrophysiology could influence circadian rhythms.
#### Room 3
* **Ilir Dema**: A regulatory network based FitzHugh-Nagumo model.  Neurons are the principal elements that make up virtually every nervous system in existence. Hence, finding novel ways to effectively reproduce the dynamics of individual neurons is of paramount importance for computational neuroscience.  The FitzHugh-Nagumo model is a first order non-linear system of ODEs which is a simplified version of the system of ODEs developed by Hodgkin and Huxley for modelling the behaviour of neurons when firing/resting.  Applying novel methods based on dynamical systems generated by regulatory networks, based on the fertile ground of the intersection of graph theory, algebra, and dynamical systems, we show that it is possible to derive a class of dynamical system that exhibit precisely same dynamics as the original FitzHugh-Nagumo model, based only on the behaviour of sodium/potassium channels.
* **Aref Pariz**: Stimulation (TES) and transcranial magnetic stimulation (TMS) are promising non-invasive treatments for neurological and neuropsychiatric disorders. Although amplified interest and reports about their effectiveness, little is known about how they engage and interfere with both individual and populations of neurons and how TES engages brain plasticity. Ubiquitous neural diversity and heterogeneity, related to morphology, function, and intrinsic cellular features, result in widely distinctive responses to stimuli and thus may well influence the effectiveness of therapeutic approaches that pertain to plasticity. As a first approach to this problem, we study the effect of tACS on individual and coupled neurons. We use the Hebbian STDP rule to reflect plastic changes in network connectivity based on a leaky integrate and fire neuron model. Focusing on the asynchronous regime, we explored the response of both individual cells and populations to periodic stimulation of varying intensities and frequencies - and how such responses can be impacted by heterogeneity. Stimulation response depends on the incoming stimulation frequency and membrane time constant. However, stimulating two neurons coupled bidirectionally with chemical synapses, different time constants of neurons, enable stimulation to selectively potentiate synapses from a neuron with a lower time constant (faster and more responsive to the stimulation) to the neuron with a higher time constant (slower) using adequately tuned stimuli. This effect can alter the structural connectivity of the neural network, providing important insight into how to use TES to influence plasticity and stabilize stimulation-induced changes in brain connectivity.
