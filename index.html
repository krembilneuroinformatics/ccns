<!doctype html><html><head><meta name=generator content="Hugo 0.115.4"><title>Canadian Computational Neuroscience Spotlight</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=no"><link rel=stylesheet href=https://krembilneuroinformatics.github.io/ccns/assets/css/main.css><noscript><link rel=stylesheet href=https://krembilneuroinformatics.github.io/ccns/assets/css/noscript.css></noscript><style>:root{--site-background:url("https://krembilneuroinformatics.github.io/ccns/images/new_canada_2.jpg")}</style><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script></head><body class=is-preload><div id=wrapper><header id=header><div class=logo><a href=/><span class="icon fa-"></span></a></div><div class=content><div class=inner><h1>Canadian Computational Neuroscience Spotlight</h1><p>V4 taking place October 5-6 2023. Register at crowdcast.io/c/ccnsv4</p></div></div><nav><ul><li><a href=#01-about-ccns>01-About CCNS</a></li><li><a href=#02-organizing-committee>02 - Organizing Committee</a></li><li><a href=#03-speaker-spotlight>03- Speaker Spotlight</a></li><li><a href=#04-ccns-2022-program>04 - CCNS 2022 Program</a></li><li><a href=#05-past-future>05 - Past & Future</a></li></ul></nav></header><div id=main><article id=01-about-ccns><h2 class=major>01-About CCNS</h2><span class="image main"><img src alt></span><p>The Canadian Computational Neuroscience Spotlight (CCNS) was created following the mass cancellations and postponements
of traditional neuroscience conferences during the early stages of the COVID-19 pandemic, including two such meetings
amongst the Canadian neuroscience community. The absence of these meetings presented an opportunity to create a brand-new,
entirely virtual academic meeting that could take full advantage of the online setting. Given that traditionally-defined
trainees and early-career researchers were arguably most impacted by the cancellation of the networking and learning
opportunities that conferences present, CCNS was designed as a “trainee-focused” meeting, highlighted by tutorial talks
beginning each session, panel discussions with both established and early-career scientists, and a spotlight on trainee
presentations.</p><p>The <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008485">first edition of CCNS</a> was planned and implemented entirely in ten weeks and yielded a meeting with more than 450
registrants, including representation from every continent across the globe. Perhaps most importantly, the limited costs
of the virtual setting allowed the meeting to be completely free of charge for all attendees. Every element of the meeting
remains available for replay online, another benefit of the virtual setting. This success served as the impetus for making
CCNS a recurring academic meeting.</p><p>Going forward, CCNS will continue to highlight cutting-edge computational neuroscience research, both in Canada and around
the world, while providing unique learning, networking, and presentation opportunities for early-career researchers. The
meeting is committed to remaining cost-accessible to the entire academic community, using the virtual setting to maximize
accessibility for populations for which physical conferences present a challenge, and maintaining a gender-balanced and
diverse lineup of speakers during its continued evolution.</p></article><article id=02-organizing-committee><h2 class=major>02 - Organizing Committee</h2><span class="image main"><img src alt></span><figure class="image main"><img src=images/screenshot.png></figure><h2 id=about-the-organizing-committee>About the Organizing Committee</h2><p><a href=http://scottrich.strikingly.com/><strong>Dr. Scott Rich</strong></a> (<a href=https://twitter.com/RichCompNeuro>@RichCompNeuro</a>, <em><strong>CCNS lead organizer</strong></em>) is currently a Postdoctoral Research Fellow and Neuron to Brain laboratory team lead at the Krembil Brain Institute.
His research aims to elucidate the multi-scale interactions driving physiological brain activity by better understanding how they are disrupted in epilepsy, a distinctly multi-scale pathology. This work includes a focus on distinctly human epilepsy by integrating human electrophysiological data into the modeling process at varied spatial scales, ranging from biophysically detailed single neuron models to neural mass models.</p><p><a href=cognemo.com><strong>Dr. Andreea Diaconescu</strong></a> (<a href=https://twitter.com/cognemo_andreea>@cognemo_andreea</a>, <em><strong>CCNS co-organizer</strong></em>) is currently an Independent Scientist at the Krembil Centre for Neuroinformatics at the Centre for Addiction and Mental Health. Leading the Cognitive Network Modelling team, her research focuses on developing cognitive tasks and computational models that address specific symptoms in psychiatry with a particular focus on delusions. In combination with neuroimaging and electrophysiological recordings, the aim is to assess the clinical utility of these models in prospective patient studies</p><p><a href=grifflab.com><strong>Dr. John Griffiths</strong></a> (<a href=https://twitter.com/neurodidact>@neurodidact</a>, <em><strong>CCNS co-organizer</strong></em>) is a cognitive and computational neuroscientist, with particular research interests in mathematical modelling of large-scale neural dynamics, multimodal neuroimaging data analysis methods, and brain stimulation in the context of neuropsychiatric and neurological disease. He is currently an Independent Scientist at the Krembil Centre for Neuroinformatics at CAMH, where he leads a team focused on whole-brain and multi-scale neurophysiological modelling. He is also an Assistant Professor in the University of Toronto Departments of Psychiatry and Institute of Medical Sciences.</p><p><a href=https://sites.google.com/view/lnsbsp/home><strong>Dr. Milad Lankarany</strong></a> (<a href=https://twitter.com/MLankarany>@MLankarany</a>, <em><strong>CCNS co-organizer</strong></em>) is an Assistant Professor at the University of Toronto Instiute of Biomaterials and Biomedical Engineering, and a Scientist at the Krembil Brain Institute. The main focus of his lab&rsquo;s work is to uncover information processing mechanisms of neural systems. His goal is to understand how information is represented, propagated and computed. Understanding neural information processing will result in the development of computational algorithms and engineering techniques for the optimal controlling of the functionality of neural systems. For example, closed loop neuro-stimulators can be used to adaptively intervene with the neural system of patients with neurological disorders in order to restore the normal activity.</p></article><article id=03-speaker-spotlight><h2 class=major>03- Speaker Spotlight</h2><span class="image main"><img src alt></span><figure class="image main"><img src=images/SessionChairs_v1.png></figure><h2 id=ccnsv3-external-session-chairs>CCNSv3 External Session Chairs</h2><p><a href=https://twitter.com/Alex_Pierri_C><strong>Dr. Alexandra Chatzikalymniou</strong></a>: Dr. Chatzikalymniou has a Bachelor&rsquo;s Degree in Chemical Engineering from the University of Patras, Greece. She completed her PhD at the University of Toronto under the supervision of Dr. Frances Skinner, where she investigated the generation mechanism of theta rhythms in the hippocampus. She is currently a postdoctoral fellow at Stanford University at the lab of Dr. Ivan Soltesz, where she studies hippocampal sharp-wave ripples during behavior.</p><p><a href=https://www.armcintosh.com/home><strong>Dr. Randy McIntosh</strong></a>: Dr. McIntosh&rsquo;s research program involves computational modeling and brain imaging to explore changes in cognition across the lifespan and changes in the face of brain damage or disease. The program builds on an international collaboration that delivered TheVirtualBrain (thevirtualbrain.org) and integrates research efforts globally to accelerate research and translation. The goals are 1) to integrate the modeling platform into the standard workflow for clinical decision support, and 2) develop a cloud-based system where anyone can create brain models for research, clinical use, or education.</p><p><a href=https://cognemo.com/karvelis/><strong>Dr. Povilas Karvelis</strong></a>: Dr. Povilas Karvelis is a Postdoctoral Research Fellow at the Cognitive Network Modelling lab at the Krembil Centre for Neuroinformatics at the Centre for Addiction and Mental Health. His primary research is focused on developing computational models of the vulnerabilities underlying suicidality. The purpose of these models is two-fold. First, it can help formalize our understanding of suicidality across different levels of analysis (neural, behavioral, phenomenological, social). Second, these exact models could (eventually) be used in clinical practice to aid diagnosis and guide personalized care.</p><h2 id=speakers-for-ccnsv3>Speakers for CCNSv3</h2><ul><li><a href=https://www.ece.utoronto.ca/people/wong-w/><strong>Dr. Willy Wong</strong></a>: Willy Wong received his BSc in physics from the University of Toronto, following that his masters and doctoral degrees with Ken Norwich in physics and biomedical engineering at the Institute of Biomedical Engineering (BME) at U of T. Since then he was a visiting scientist at universities in Toyama (Japan), Cambridge (U.K.) and Eindhoven (The Netherlands) working with such notable sensory scientists as Horace Barlow and Adrian Houtsma. Since 2000, he joined the ECE department at U of T as a faculty member. Dr. Wong’s research focuses on neural engineering, biomedical signal processing and on sensory physics, with particular emphasis on characterizing brain electrical activity, elucidating underlying mechanisms and building associated medical devices.</li><li><a href=http://prescottlab.ca/><strong>Dr. Steven Prescott</strong></a>: Steven Prescott is a Senior Scientist in Neurosciences and Mental Health at the Hospital for Sick Children and Professor of Physiology and Biomedical Engineering at the University of Toronto. He completed his MD/PhD at McGill University, where his doctoral research focused on pain processing in the spinal cord. He opted not to pursue a clinical medicine and focused instead on fundamental research. He undertook postdoctoral training in computational neuroscience at the Salk Institute in San Diego before starting his own lab at the University of Pittsburgh. In 2012, he moved to SickKids. His lab seeks to uncover how somatosensory information in normally encoded and how disruption of that coding contributes to neuropathic pain. His lab combines a variety of experimental techniques (electrophysiology, calcium imaging, optogenetics) with computational modeling</li><li><a href="https://www.medschool.lsuhsc.edu/cell_biology/faculty_detail.aspx?name=canavier_carmen"><strong>Dr. Carmen Canavier</strong></a>: Dr. Canavier is a theoretical and computational neuroscientist who is interested in nonlinear neuronal dynamics and synchronization of pulse coupled oscillators. She works on delineating the biophysical basis for diversity in subpopulations of midbrain dopamine neurons, on mechanisms of hippocampal gamma oscillations, and on neuromodulation of intrinsic dynamics. She received her PhD in electrical and computer engineering from Rice University and did her postdoctoral research at the University of Texas Health Sciences Center at Houston. She is the Mullins Professor and Interim Head of the Department of Cell Biology and Anatomy at LSU Health Sciences Center in New Orleans.</li><li><a href=https://www.mn.uio.no/fysikk/english/people/aca/geinevol/index.html><strong>Dr. Gaute Einevoll</strong></a>: Gaute Einevoll is a professor of physics at the Norwegian University of Life Sciences and the University of Oslo working on brain physics, in particular, physics-type modelling of nerve cells, networks of nerve cells, brain tissue and brain signals. He is participating in the large-scale EU Human Brain Project started in 2013 and scheduled to end in 2023.</li><li><strong>Dr. Richard Naud</strong>: Richard Naud is originally from Montreal. He studied Physics and Neuroscience at McGill, EPFL, Cambridge (UK) and TU Berlin. His lab at the University of Ottawa focuses on the learning and the information processing capabilities of neuronal networks</li><li><strong>Dr. Milad Lankarany</strong>: See bio under &ldquo;Organizing Committee&rdquo; tab</li><li><a href=https://mila.quebec/en/person/blake-richards/><strong>Dr. Blake Richards</strong></a>: Blake Richards is an Assistant Professor in the School of Computer Science and The Neuro at McGill University. He is also a Core Faculty Member at Mila where he holds a CIFAR Canada AI Chair. Dr. Richards was the 2019 Canadian Association for Neuroscience Young Investigator Award Recipient, and is known for his work at the intersection of neuroscience and AI.</li><li><a href=http://www.nicolacomputationalneurosciencelab.com/><strong>Dr. Wilten Nicola</strong></a>: Dr. Wilten Nicola is a Tier II Canada Research Chair in Computational Neuroscience, at the University of Calgary, in the Cumming School of Medicine. Dr. Nicola specializes in researching how neurons come together into functional circuits by using techniques in applied mathematics, dynamical systems theory, and machine learning.</li><li><a href=https://www.sfu.ca/neuro-institute/about/governance/staff/kelly-shen.html><strong>Dr. Kelly Shen</strong></a>: Dr. Kelly Shen is the Senior Program Manager and Informatics Team Lead for the Institute for Neuroscience and Neurotechnology at Simon Fraser University. She led the development of The Virtual Macaque Brain, a macaque connectome for modelling brain dynamics in TheVirtualBrain. More recently, her research has focused on understanding the network dynamics that underlie cognitive function in aging and dementia and has led the development of an automated multi-modal MRI pipeline for processing ‘big data’ inputs for large-scale modelling.</li><li><a href=https://www.linkedin.com/in/davide-momi-748698ba><strong>Dr. Davide Momi</strong></a>: Davide is a Post-Doctoral Research Fellow at the Krembil Centre for Neuroinformatics, experienced with multimodal neuroimaging and electrophysiological data, brain stimulation, quantitative structural MRI assessment, machine learning, and simulations of macroscale brain dynamics. His research is focused on predicting TMS signal propagation based on neuroimaging and electrophysiological data.</li><li><a href=https://github.com/estefanysuarez><strong>Laura Suarez</strong></a>: Laura Suárez is a PhD candidate in the Neuroscience program at McGill University. Her background is engineering and her main interests lie at the intersection of artificial intelligence and neuroscience. Her research revolves around the link between structure and function in biological brain networks. Specifically, how network structure and dynamics interact to shape the computational capacity of biological neural networks, and how this can help to establish novel design principles for better neuromorphic architectures. Her work is currently supervised by Dr. Bratislav Mišić from the Montreal Neurological Institute (MNI), and by Dr. Guillaume Lajoie from the Montreal Institute for Learning Algorithms (Mila).</li><li><a href=https://www.uottawa.ca/brain/people/lefebvre-jeremie><strong>Dr. Jeremie Lefebvre</strong></a>: Dr. Lefebvre is an Associate Faculty of the Department of Biology of the University of Ottawa. His team uses interdisciplinary methods to characterize fluctuations in brain activity to better understand their involvement in brain health and diseases, collaborating with international teams of experimentalists and clinicians in the fields of cognitive neuroscience, neuroimaging and brain stimulation.</li><li><a href=https://ins-amu.fr/jirsaviktor><strong>Dr. Viktor Jirsa</strong></a>: Dr. Viktor Jirsa is the director of research at the French National Centre for Scientific Research and director of the Institut de Neurosciences des Systemes at Ax-Marseille Universite. His work linking neural networks to brain function includes curating The Virtual Brain neuroinformatics platform and applications of this tool to the study of epilepsy.</li><li><strong>Dr. Jacqueline Scholl</strong>: Jacqueline Scholl investigated the neural and pharmacological mechanisms of learning and decision-making using functional MRI, MRI spectroscopy and drug manipulations during her doctoral research. Since then she has been examining the neural mechanisms of attributional styles in depression and how the brain uses emotions to prioritize behaviours. In April 2022, she moved to the Lyon Neuroscience Research Centre (France) to take up a staff scientist position.</li><li><a href=http://casperhesp.nl/><strong>Casper Hesp</strong></a>: Casper Hesp double-majored in Cognitive Neuroscience and Computational Astrophysics (Cum Laude; University of Amsterdam) and then received a 4-year Research Talent Grant from the Dutch Government to simulate the self-organisation of deep social cognition in open-ended virtual environments. Casper currently has over 6 years of experience in high-end computational modelling and algorithmic innovation. His published works have advanced the frontiers of deep active inference towards novel bio-inspired models of affect, meta-awareness, and collective behaviour.</li><li><strong>Dr. Andreea Diaconescu</strong>: See bio under &ldquo;Organizing Committee&rdquo; tab</li><li><a href=https://www.utsc.utoronto.ca/psych/person/cendri-hutcherson><strong>Dr. Cendri Hutcherson</strong></a>: Cendri Hutcherson is the director of the Toronto Decision Neuroscience Laboratory and an Associate Professor of Psychology at the University of Toronto. Her research program applies computational modeling to behavior, eye tracking, EEG, and fMRI data, with the goal of understanding how we make decisions and why we sometimes make decisions we later regret.</li></ul></article><article id=04-ccns-2022-program><h2 class=major>04 - CCNS 2022 Program</h2><span class="image main"><img src alt></span><h3 id=ccnsv3-will-take-place-on-june-6-7-2022-and-registration-is-open-herehttpswwwcrowdcastioeccnsv3register>CCNSv3 will take place on June 6-7, 2022, and registration is open <a href=https://www.crowdcast.io/e/ccnsv3/register>here</a>.</h3><h3 id=submit-your-abstract-for-a-trainee-talk-herehttpsformsglethszwmyr4uxhqlji9-by-may-23-for-full-consideration>Submit your abstract for a Trainee Talk <a href=https://forms.gle/thSZWMyr4uxHQLJi9>here</a> by May 23 for full consideration.</h3><h2 id=program>Program</h2><h3 id=monday-june-6>Monday, June 6</h3><ul><li>8:45 AM EDT: <strong>Welcome and Introduction: Dr. Scott Rich</strong></li><li>9:00 AM EDT: <strong>Tutorial Talk: Dr. Alexandra Chatzikalymniou</strong> (Neural Circuit Modeling)</li><li>9:25 AM EDT: <strong>Dr. Willy Wong</strong> (Neural Circuit Modeling)</li><li>9:50 AM EDT: <strong>Break</strong></li><li>10:00 AM EDT: <strong>Dr. Steven Prescott</strong> (Neural Circuit Modeling)</li><li>10:25 AM EDT: <strong>Dr. Carmen Canavier</strong> (Neural Circuit Modeling)</li><li>10:50 AM EDT: <strong>Break</strong></li><li>11:00 AM EDT: <strong>Keynote Address: Dr. Gaute Einevoll</strong> (Neural Circuit Modeling)</li><li>12:00 PM EDT: <strong>Lunch Break</strong></li><li>1:00 PM EDT: <strong>Tutorial Talk</strong> (Neuro-AI)</li><li>1:25 PM EDT: <strong>Dr. Richard Naud</strong> (Neuro-AI)</li><li>2:00 PM EDT: <strong>Break</strong></li><li>2:10 PM EDT: <strong>Dr. Milad Lankarany</strong> (Neuro-AI)</li><li>2:45 PM EDT: <strong>Dr. Blake Richards</strong> (Neuro-AI)</li><li>3:20 PM EDT: <strong>Break</strong></li><li>3:25 PM EDT: <strong>Dr. Wilten Nicola</strong> (Neuro-AI)</li><li>4:00 PM EDT: <strong>Break</strong></li><li>4:05 PM EDT: <strong>Trainee Spotlight Talks: Laura Medlock and Ann Huang</strong></li><li>4:40 PM EDT: <strong>Parallel Trainee Talks</strong></li></ul><h3 id=tuesday-june-7>Tuesday, June 7</h3><ul><li>8:40 AM EDT: <strong>Trainee Spotlight Talks: Andrea Luppi and Annemarie Wolff</strong></li><li>9:15 AM EDT: <strong>Parallel Trainee Talks</strong></li><li>9:45 AM EDT: <strong>Break</strong></li><li>9:50 AM EDT: <strong>Tutorial Talk: Dr. Kelly Shen</strong> (Large-Scale Brain Modeling)</li><li>10:15 AM EDT: <strong>Dr. Davide Momi</strong> (Large-Scale Brain Modeling)</li><li>10:40 AM EDT: <strong>Break</strong></li><li>10:50 AM EDT: <strong>Laura Suarez</strong> (Large-Scale Brain Modeling)</li><li>11:15 AM EDT: <strong>Dr. Jeremie Lefebvre</strong> (Large-Scale Brain Modeling)</li><li>11:40 AM EDT: <strong>Break</strong></li><li>11:50 PM EDT: <strong>Keynote Address: Dr. Viktor Jirsa</strong> (Large-Scale Brain Modeling)</li><li>12:50 PM EDT: <strong>Lunch Break</strong></li><li>1:20 PM EDT: <strong>Panel Discussion</strong></li><li>2:00 PM EDT: <strong>Dr. Jacqueline Scholl</strong> (Cognitive Modeling)</li><li>2:35 PM EDT: <strong>Casper Hesp</strong> (Cognitive Modeling)</li><li>3:10 PM EDT: <strong>Break</strong></li><li>3:20 PM EDT: <strong>Tutorial Talk: Dr. Andreea Diaconescu</strong> (Cognitive Modeling)</li><li>3:45 PM EDT: <strong>Break</strong></li><li>3:50 PM EDT: <strong>Keynote Address: Dr. Cendri Hutcherson</strong> (Cognitive Modeling)</li><li>4:50 PM EDT: <strong>Concluding Remarks</strong></li></ul><h2 id=trainee-abstracts>Trainee Abstracts</h2><h3 id=monday-spotlight-talks>Monday Spotlight Talks</h3><ul><li><strong>Laura Medlock</strong>: Pain-related sensory input is processed in the spinal dorsal horn (SDH) before being relayed to the brain. That processing profoundly influences whether tactile stimuli are correctly or incorrectly perceived as painful. Different types of excitatory and inhibitory neurons have been identified in the SDH, and some of their connectivity is understood, but how the overall circuit processes sensory input or how that processing is disrupted under chronic pain conditions remains unclear. To explore sensory processing in the SDH, we developed a computational model of the circuit that is tightly constrained by experimental data. Our model comprises conductance-based neuron models that reproduce the characteristic firing patterns of spinal neurons. Different spinal neuron populations were synaptically connected according to available qualitative data. Using a genetic algorithm, synaptic weights were optimized to reproduce projection neuron firing rates (model output) in response to primary afferent firing rates (model input) across a range of mechanical stimulus intensities. This optimization revealed that distinct synaptic weight combinations could produce equivalent SDH circuit function, revealing degeneracy that may underlie heterogeneous responses of different circuits to perturbations or pathological insults. To validate our model, we verified that it responded to reduction of inhibition (i.e. disinhibition) and ablation of specific neuron types in a manner consistent with experiments. Our validated model offers a valuable resource for interpreting experimental results and testing hypotheses in silico to plan experiments for examining normal and pathological SDH circuit function.</li><li><strong>Ann Huang</strong>: The ability to encode “what happened when” is central to the accurate representation of episodic memory. Previous neurophysiology studies have reported groups of cells that fire sequentially during the delay period of working memory tasks. These cells are commonly called “time cells” because they are thought to serve as the neural substrates for tracking time. However, the representation of time in “time cells” is confounded by other task variables, such as the animal’s running speed, spatial location, and sensory experience. Previous studies that used statistical methods to parse the information encoded by “time cells” are also fundamentally flawed in their statistical assumptions. Here we hypothesize that rather than encoding the time elapsed per se, the so-called “time cells” emerge as an epiphenomenon when encoding any behaviorally relevant variables that unroll over time. We trained an artificial agent on a Trial-Unique Nonmatch-to-Location (TUNL) working memory task and recorded the activity from the recurrent neural network of the artificial agent. Using neuroscience-based and information-theoretic analysis, we showed that (1) apparent “time cells” emerge in the recurrent neural network during the task (2) “time cells” show heterogeneous representations of time elapsed, spatial location, and incoming sensory stimuli (3) the apparent “time cells” are more strongly modulated by spatial location rather than time elapsed during the task. Our study serves as a proof of principle that in recurrent neural networks trained on working memory tasks, the apparent “time cells” represent behaviorally relevant variables that unfolds in time rather than the time elapsed per se.</li></ul><h3 id=tuesday-spotlight-talks>Tuesday Spotlight Talks</h3><ul><li><strong>Andrea Luppi</strong>: A fundamental question in neuroscience is how brain organisation gives rise to humans’ unique cognitive abilities. Although complex cognition is widely assumed to rely on frontal and parietal brain regions, the underlying mechanisms remain elusive: current approaches are unable to disentangle different forms of information processing in the brain. Here, we introduce a powerful framework to identify synergistic and redundant contributions to neural information processing and cognition. Leveraging multimodal data including functional MRI, PET, cytoarchitectonics and genetics, we reveal that synergistic interactions are the fundamental drivers of complex human cognition. Whereas redundant information dominates sensorimotor areas, synergistic activity is closely associated with the brain’s prefrontal-parietal and default networks; furthermore, meta-analytic results demonstrate a close relationship between high-level cognitive tasks and synergistic information. From an evolutionary perspective, the human brain exhibits higher prevalence of synergistic information than non-human primates. At the macroscale, we demonstrate that high-synergy regions underwent the highest degree of evolutionary cortical expansion. At the microscale, human-accelerated genes promote synergistic interactions by enhancing synaptic transmission. These convergent results provide critical insights that synergistic neural interactions underlie the evolution and functioning of humans’ sophisticated cognitive abilities, and demonstrate the power of our widely applicable information decomposition framework.</li><li><strong>Annemarie Wolff</strong>: Studies of perception and cognition in schizophrenia (SCZ) show neuronal background noise (ongoing activity) to intermittently overwhelm the processing of external stimuli. This increased noise, relative to the activity evoked by the stimulus, results in temporal imprecision and higher variability of behavioral responses. What, however, are the neural correlates of temporal imprecision in SCZ behavior? We first report a decrease in electroencephalography signal-to-noise ratio (SNR) in two SCZ datasets and tasks in the broadband (1–80 Hz), theta (4–8 Hz), and alpha (8–13 Hz) bands. SCZ participants also show lower inter-trial phase coherence (ITPC)— consistency over trials in the phase of the signal—in theta. From these ITPC results, we varied phase offsets in a computational simulation, which illustrated phase-based temporal desynchronization; our simulations show that higher phase shifting leads to lower phase coherence over trials. This modeling also provided a necessary link to our results and showed decreased neural synchrony in SCZ in both datasets, sensory modalities (visual, auditory) and tasks when compared with healthy controls. Finally, we showed that reduced SNR and ITPC are related and showed a relationship to temporal precision on the behavioral level, namely reaction times. Interestingly, ITPC and SNR predict reaction times in healthy controls, but not in SCZ participants. In conclusion, we demonstrate how temporal imprecision in SCZ neural activity—reduced relative signal strength and phase coherence—mediates temporal imprecision on the behavioral level.</li></ul><h3 id=monday-parallel-talks>Monday Parallel Talks</h3><h4 id=room-1>Room 1</h4><ul><li><strong>Pascal Helson</strong>: Parkinson&rsquo;s Disease (PD) is known for its motor symptoms. However, many reasons (non-motor symptoms, brain-wide projections of neuromodulators such as dopamine, complexity of brain regions (BRs) interactions) suggest that many BRs are simultaneously affected in PD. Despite that, most research on PD is concentrated on basal ganglia and sensorimotor BRs. In this study, we aim at getting more insights into neuronal activity changes distributed across the whole brain in PD. To do so, we performed a source level analysis on resting state magnetoencephalogram (MEG) from two groups: PD patients and healthy controls. After a spectral analysis, we quantified the aperiodic activity by fitting a power law (κ/f^λ) to the MEG spectrum and then studied its relationship with age and UPDRS. Consistent with previous results, the most significant spectral changes were observed in the low alpha-band (8-10Hz) in all BRs. On the other hand, recent work has shown that the aperiodic part of the spectrum, usually ignored, allows inferring the Excitation-Inhibition (EI) ratio through λ. We found that in all but frontal regions, λ was significantly larger in PD patients than in control subjects. Larger value of λ in PD implies reduced excitation or increased inhibition or both. Furthermore, λ was correlated with patient age and UPDRS. Our results indicate for the first time that PD is associated with change in EI ratio across the whole brain. Moreover, our results provide means to extract new information from MEG which can be used in modelling and developed into new biomarkers of PD.</li><li><strong>Afroditi Talidou</strong>: The generation and propagation of action potentials in white matter are influenced by a fatty substance, called myelin, wrapping around axons. Myelin is formed by glial cells &ndash; oligodendrocytes &ndash; and allows action potentials to transmit faster and without attenuation. An important feature of myelin is its impact on conduction delays, that is, the time it takes for action potentials to reach their destination. Conduction delays play an important role in brain function due to the dependence of neural communication on spike timing. Thus studying conduction delays is of the utmost importance. Previous studies examining action potential propagation along myelinated axons are based on stereotyped cases assuming that myelin sheaths are periodically located along axons and are thus very symmetric. The question we aim to answer is: do changes in myelin segment distribution, length and thickness, not only along the same axon but also along different axons, influence conduction delays and neural communication across the white matter? We are making a step forward answering this question and estimate conduction delays and the corresponding conduction velocity in the more general case where myelin sheaths of different longitudinal lengths and widths are randomly distributed along single axons. The lengths of nodes of Ranvier, namely the gaps between two consecutive myelin, will also change. How will this impact the propagation of action potentials? What are other parameters affecting conduction delays? We approach the problem using the cable equation and provide both computational and mathematical analysis whenever possible.</li><li><strong>Loïc Azzalini</strong>: Background: Thanks to massively parallel computational architectures and spike-based communication, neuromorphic hardware holds great promise in the field of computational neuroscience to simulate large neural models in real-time. Dedicated hardware allows models of the brain to be placed in the physical world where environmental effects and interactions may be investigated. The exploration of deep brain stimulation (DBS) effects lends itself well to such brain-in-the-loop simulation. To this end, it is crucial to first simulate realistic neuronal dynamics on neuromorphic hardware. Hypothesis: Neuromorphic hardware provides a biophysically realistic computational framework to study the effects of deep brain stimulation in real-time. Materials and Methods: Recent work explored the role played by DBS-induced short-term synaptic plasticity (STP) in single-neuron recordings from patients with movement disorders. The computational framework used in this study is revisited and made compatible to run on the SpiNNaker neuromorphic hardware. Specifically, the sPyNNaker computational framework is extended to support DBS-induced plasticity and STP, based on the phenomenological Tsodyks-Markram (TM) model. Results: We recently implemented STP dynamics for the SpiNNaker system which previously only supported long-term plasticity (e.g. STDP). Building on this milestone, we developed a model for DBS-induced STP. Conclusion: Moving forward, we aim to implement a model of the basal ganglia neuronal network using biophysically realistic models developed in the NSBSPL. This will support investigations into DBS impact, in real-time, on different substructures of the basal ganglia and at different scales.</li></ul><h4 id=room-2>Room 2</h4><ul><li><strong>Benjamin Barlow</strong>: In a variety of neurons, action potentials (APs) initiate at the proximal axon, within a region called the axon initial segment (AIS). Pyramidal neurons concentrate high-threshold sodium channels (Nav1.2) in the proximal AIS, and the distal AIS contains mostly lower threshold Nav1.6. It has been argued that this separated Nav distribution favours backpropagation. However, our simulations show that this distribution actually impedes backpropagation when the neuron is stimulated somatically. We implemented a range of hypothetical Nav distributions in the AIS of a multicompartmental pyramidal cell model. When a stimulating current is injected at the soma, the intrinsic right-shift of Nav1.2 activation causes these channels to raise the backpropagation threshold. However, with axonal stimulation, the right-shift of Nav1.2 availability dominates, such that concentrating Nav1.2 in the proximal AIS promotes backpropagation. Our results imply that regulation of Nav separation can sensitively control backpropagation.</li><li><strong>Chitaranjan Mahapatra</strong>: Mathematical Modeling of Putative Coupling between cAMP/PKA Pathway and T- Type Ca2+ Channels to Investigate Excitability Properties in Layer II Stellate Cells The firing patterns of stellate cells in layer II of medial entorhinal cortex are involved in memory, cognition and perception. These patterns are largely modulated by the underlying subcellular calcium dynamics within the axon initial segment (AIS). Recent experimental data have suggested a putative coupling between dopamine D2 receptors (D2R) and T-type Ca2+ channels via a series of sub cellular mechanisms as another biophysical explanation for the firing pattern modulation. Both the cAMP-PKA pathway and the calcium influx are involved in D2R -induced firing pattern alternations. This in silico study aims to enhance our understanding of the calcium influx through T-type Ca2+ channels via cAMP-PKA pathway within AIS of the layer II stellate cells. This simulation study also shows their modulating effects on resting membrane potential (RMP) and action potential (AP) plasticity in pathological conditions.</li><li><strong>Zhenyang Sun</strong>: Reduced but not diminished: single-compartment oriens lacunosum-moleculare (OLM) cell model captures detailed model behavior and explains theta resonance in OLM cells Authors: Zhenyang Sun, Frances K Skinner Abstract: Conductance-based cell models enable theoretical explorations in experimentally untenable situations. With advances in cell imaging and computational power, multi-compartment models with morphological accuracy are becoming common practice. Details increase model biophysical accuracy, but also muddle interpretability. Thus, model reduction is necessary to find the balance between biophysical fidelity and understanding. We use our developed state-of-art multi-compartment OLM cell model and reduce it to a single compartment model via “biophysical preservation constraints”, and using current injection data as a basis for comparison. We examine the biophysical fidelity of the reduced model by comparing analyses using it with those done using the full, multi-compartment model. Our reduced model produces results comparable to that of the full model. That is, it can capture both in vitro and in vivo complex behaviors of the original model as well as a theta frequency spiking resonance, defining feature of the OLM cell type. We then use the reduced model to show that hyperpolarization-activated inward channels could be responsible for preference to theta resonant frequencies. In addition to further analyses to decipher the interacting biophysical dynamics, this reduced model could be used as a template to interface with experimental recordings for direct parameter estimation of biophysical characteristics.</li></ul><h4 id=room-3>Room 3</h4><ul><li><strong>Akram Shourkeshti</strong>: In uncertain environments, we generally exploit rewarding opportunities but sometimes explore uncertain alternatives that could be better. At the onset of exploration, neuronal activity patterns in the prefrontal cortex suddenly disorganize, which could promote discovery and learning. Although the mechanisms behind this disorganization remain unknown, one possibility is pupil-linked neuromodulatory systems. However, it is not clear whether pupil size predicts neural signatures of exploration or transitions to exploration. Here, we simultaneously measured pupil size and neuronal activity in the prefrontal cortex while two rhesus macaques made decisions in a dynamic environment that encouraged both exploration and exploitation. We found that pupil size was larger during exploration than exploitation and predicted disorganized patterns of prefrontal activity in both single neurons and populations. The pupil also exhibited surprising trial-by-trial dynamics: it grew larger across trials before exploration, then abruptly decreased to below-baseline levels. Because pupil size dropped immediately after the first explore trial, pupil-linked mechanisms may anticipate the start of exploration, without being sustained throughout periods of exploration. Pupil size predicted our observation of a general slowdown of both response time and neural activity before the start of exploration, suggesting that the onset of exploration signals a critical &ldquo;tipping point&rdquo; in prefrontal dynamics. In sum, we found that pupil size tracked both exploratory behavior and its neural correlates, supporting models linking pupil-linked mechanisms with these phenomena. However, the trial-by-trial dynamics of these effects implicate pupil-linked mechanisms in the critical transition at the onset of exploration, rather than in sustaining exploration over time.</li><li><strong>Leanne Monteiro</strong>: There are well-known sex differences in visual perception, and the visual cortex (V1C) is >20% larger in males than females. Nevertheless, the issue of sex differences in V1C development has not been well-studied. Myelin is a complex multiprotein that has been shown to serve multiple roles in V1C development and plasticity. In the critical period, an increase in myelin-derived signaling puts the ‘brakes’ on developmental plasticity. Paradoxically, in adult V1C, myelin increases in response to enriched sensory experience suggesting that it facilitates plasticity. Together, these raise the question of whether the molecular composition of myelin differs by age and sex? To address this, we analyzed the development of 58 myelin-associated genes using a transcriptomic database from post-mortem tissue samples of the human V1C (n=48). We characterized the lifespan changes by fitting locally estimated scatterplot smoothing curves for each gene and sex pair. We noticed that while some genes showed monotonic increase/decrease across the lifespan, others had an undulating pattern unique to adolescence coinciding with the end of the sensitive period in the human V1C. Second, we conducted hierarchical clustering and found 8 distinct trajectories that describe the developmental profile of myelin. We listed the genes in each trajectory cluster and found minimal overlap between the sexes. This trajectory analysis identified robust age- and sex-related differences in the development of myelin genes in human V1C. These novel findings suggest that myelin may play different roles in transitioning from juvenile to adult plasticity in V1C of females and males.</li><li><strong>Urvi Mishra</strong>: Title: Classification of motor planning into overt or imagery using an ECoG signal ECoG provides a fine spatial and temporal resolution of neural activity at a wide scale of locations. In the field of brain computer interfaces (BCI), this can give insight into what neural populations are active during a certain task and how their activity is characterised. Neurally integrated robotic prosthetics hold the potential to help people better regain lost function compared to traditional prosthetics. In order to accurately execute movement, the prosthetic must “know” whether a person means to move now, intends to move later, or is just thinking about a movement with no plan of performing it. With the motor imagery dataset, we intend to build a binary classifier to differentiate overt movement (intention to actually carry out a movement) and motor imagery (planning a movement without actually executing it). As observed in Miller et al. 2010, the spatial distribution of neural activity is similar for both overt movement or motor imagery innervating the same body part, while the PSD characteristics are different. By training the classifier, our goal is to have an accurate prediction of overt/imagery movement given the ground truth labels provided by the dataset. We will train our model on a specific body part, and see if parameters from one model generalize to another body part - in other words determining if overt or imagined movement has unique dynamics regardless of specific muscle movement.</li></ul><h3 id=tuesday-parallel-talks>Tuesday Parallel Talks</h3><h4 id=room-1-1>Room 1</h4><ul><li><strong>Parker Singleton</strong>: Psychedelics like lysergic acid diethylamide (LSD) and psilocybin offer a powerful window into the function of the human brain and mind, by temporarily altering subjective experience through their neurochemical effects. A recent model postulates that serotonin 2a (5-HT2a) receptor agonism allows the brain to explore its dynamic landscape more readily, as reflected by more diverse (entropic) brain activity. We postulate that this increase in entropy may arise in part from a flattening of the brain’s control energy landscape, which can be observed using network control theory to quantify the energy required to transition between recurrent brain states measured using functional magnetic resonance imaging (fMRI) in individuals under LSD, psilocybin, and placebo conditions. We show that LSD and psilocybin reduce the amount of control energy required for brain state transitions, and, furthermore, that, across individuals, LSD’s reduction in control energy correlates with more frequent state transitions and increased entropy of brain state dynamics. Through network control analysis that incorporates the spatial distribution of 5-HT2a receptors from publicly available (non-drug) positron emission tomography (PET) maps, we demonstrate the specific role of this receptor in reducing control energy. Our findings provide evidence that 5-HT2a receptor agonist compounds allow for more facile state transitions and more temporally diverse brain activity. More broadly, by combining receptor-informed network control theory with pharmacological modulation, our work highlights the potential of this approach in studying the impacts of targeted neuropharmacological manipulation on brain activity dynamics.</li><li><strong>Sebastian Idesis</strong>: The understanding of the stroke lesions’ consequences is limited, relying mostly on behavioral reports and mere descriptive correlational information from neuroimaging techniques. Here we demonstrate that utilizing structural disconnection maps describing the specific damages in the anatomical connectivity of individual patients crucially allows the construction of a causal mechanistic generative whole-brain model that is able to explain the functional and behavioral consequences of the stroke lesions. Classification of the stroke behavior severity showed a higher accuracy compared to the most common techniques. Using topological measures characterizing the functional effects of the damages, we were able to understand how network dynamics change emerge in a nontrivial way after a stroke injury of the underlying complex brain system. The results underlined the relevance of adding structural disconnection information to the model to allow for a more personalized treatment which in turn would lead to an improved recovery of the patients. Furthermore, it opens the possibility to apply external manipulations such as neurostimulation in order to treat such a word-wide disease as stroke lesions.</li></ul><h4 id=room-2-1>Room 2</h4><ul><li><strong>Liang Chen</strong>: In the paper, we derive and analyze a set of exact mean-field equations for the network of Izhikevich neurons, where each neuron is modelled by a two dimensional system consisting of a quadratic integrate and fire equation plus an equation which implements spike frequency adaptation. Previous work deriving a mean-field model for this type of network, relied on the assumption of sufficiently slow dynamics of the adaptation variable. However, this approximation did not succeed in establishing an exact correspondence between the macroscopic description and the realistic neural network, especially when the adaptation time constant was not large. The challenge lies in how to achieve a closed set of mean-field equations with the inclusion of the mean-field expression of the adaptation variable. We address this problem by using a Lorentzian ansatz combined with the moment closure approach to arrive at a mean-field system in the thermodynamic limit. The resulting macroscopic description is capable of qualitatively and quantitatively describing the collective dynamics of the neural network, including transition between states where the individual neurons exhibit tonic firing and bursting. We extend the approach to a network of two populations of neurons and discuss the accuracy and efficacy of our mean-field approximations by examining all assumptions that are imposed during the derivation. Numerical bifurcation analysis of our mean-field models reveal bifurcations not previously observed in the models, including a novel mechanism for emergence of bursting in the network.</li><li><strong>Alexander G Ginsberg</strong>: We present a mean-field formalism for modeling firing-rate statistics of brain regions whose neurons exhibit atypical firing patterns and heterogeneous electrophysiological properties. We apply the formalism to the suprachiasmatic nucleus (SCN)–-the human circadian pacemaker–-whose neurons can intrinsically exhibit depolarized low-amplitude membrane oscillations (DLAMOs), depolarization block (DB), and standard action potential firing at different times of day. Further, GABA reversal potentials and molecular circadian phases of SCN neurons, among other properties, vary across the network and/or slowly over time. Our formalism consists of a system of integro-differential equations describing the time evolution of the mean and standard deviation of synaptic conductances across the network. Electrophysiological properties of SCN neurons are incorporated by computing responses to synaptic conductance inputs of a Hodgkin-Huxley-type SCN neuron model that exhibits DLAMOs and DB. Such responses are then averaged over distributions of relevant quantities and included in the differential equations. Results suggest mechanisms by which physiologically relevant changes to firing activities may arise, highlighting means by which the amplitude of firing rates may shrink, the standard deviation of firing rates may grow, and by which a mid-day dip in firing rates may appear. For instance, results show that a large spread in circadian phases across SCN neurons reduces the size of oscillations in SCN network firing activity across the 24h day, identifying a mechanism by which heterogeneities in neuron electrophysiology could influence circadian rhythms.</li></ul><h4 id=room-3-1>Room 3</h4><ul><li><strong>Ilir Dema</strong>: A regulatory network based FitzHugh-Nagumo model. Neurons are the principal elements that make up virtually every nervous system in existence. Hence, finding novel ways to effectively reproduce the dynamics of individual neurons is of paramount importance for computational neuroscience. The FitzHugh-Nagumo model is a first order non-linear system of ODEs which is a simplified version of the system of ODEs developed by Hodgkin and Huxley for modelling the behaviour of neurons when firing/resting. Applying novel methods based on dynamical systems generated by regulatory networks, based on the fertile ground of the intersection of graph theory, algebra, and dynamical systems, we show that it is possible to derive a class of dynamical system that exhibit precisely same dynamics as the original FitzHugh-Nagumo model, based only on the behaviour of sodium/potassium channels.</li><li><strong>Aref Pariz</strong>: Stimulation (TES) and transcranial magnetic stimulation (TMS) are promising non-invasive treatments for neurological and neuropsychiatric disorders. Although amplified interest and reports about their effectiveness, little is known about how they engage and interfere with both individual and populations of neurons and how TES engages brain plasticity. Ubiquitous neural diversity and heterogeneity, related to morphology, function, and intrinsic cellular features, result in widely distinctive responses to stimuli and thus may well influence the effectiveness of therapeutic approaches that pertain to plasticity. As a first approach to this problem, we study the effect of tACS on individual and coupled neurons. We use the Hebbian STDP rule to reflect plastic changes in network connectivity based on a leaky integrate and fire neuron model. Focusing on the asynchronous regime, we explored the response of both individual cells and populations to periodic stimulation of varying intensities and frequencies - and how such responses can be impacted by heterogeneity. Stimulation response depends on the incoming stimulation frequency and membrane time constant. However, stimulating two neurons coupled bidirectionally with chemical synapses, different time constants of neurons, enable stimulation to selectively potentiate synapses from a neuron with a lower time constant (faster and more responsive to the stimulation) to the neuron with a higher time constant (slower) using adequately tuned stimuli. This effect can alter the structural connectivity of the neural network, providing important insight into how to use TES to influence plasticity and stabilize stimulation-induced changes in brain connectivity.</li></ul></article><article id=05-past-future><h2 class=major>05 - Past & Future</h2><span class="image main"><img src alt></span><h2 id=previous-years>Previous Years</h2><h3 id=ccns-2021>CCNS 2021</h3><p>The full program of talks at CCNSv2, including sessions chaired by Dr. Etay Hay, Dr. Maurizio de Pitta, Dr. Carmen Canavier, and Dr. Bratislav Misic, can be found <a href=https://www.crowdcast.io/e/ccnsv2/register>here</a>.</p><h3 id=ccns-2020>CCNS 2020</h3><p>The full program of talks at CCNSv1, including keynote addresses from Dr. Nancy Kopell, Dr. Dimitris Pinotsis,
Dr. Cameron McIntyre, and Dr. Philip Corlett, can be found <a href=https://www.crowdcast.io/e/CCNS/register>here</a>.</p><h2 id=future-plans>Future Plans</h2><p>CCNS will return! Check this page, or follow the organizing committee on Twitter (<a href=https://twitter.com/RichCompNeuro>@RichCompNeuro</a>, <a href=https://twitter.com/cognemo_andreea>@cognemo_andreea</a>, <a href=https://twitter.com/neurodidact>@neurodidact</a>, and <a href=https://twitter.com/MLankarany>@MLankarany</a>) for the latest updates.</p><figure class="image main"><img src=images/new_brain_3.png></figure></article></div><footer id=footer><p class=copyright><img src=https://logos-download.com/wp-content/uploads/2016/02/Twitter_Logo_new.png width=20> #CCNS</p></footer></div><div id=bg></div></body><script src=https://krembilneuroinformatics.github.io/ccns/assets/js/jquery.min.js></script>
<script src=https://krembilneuroinformatics.github.io/ccns/assets/js/browser.min.js></script>
<script src=https://krembilneuroinformatics.github.io/ccns/assets/js/breakpoints.min.js></script>
<script src=https://krembilneuroinformatics.github.io/ccns/assets/js/util.js></script>
<script src=https://krembilneuroinformatics.github.io/ccns/assets/js/main.js></script></html>